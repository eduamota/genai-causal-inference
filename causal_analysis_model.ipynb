{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6cbc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1516f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"understanding_results.pkl\", 'rb') as f:\n",
    "    df =pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad927a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b348794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c920a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnlp import CausalInferenceModel\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e545bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = CausalInferenceModel(df, \n",
    "                         metalearner_type='t-learner', learner=LGBMClassifier(num_leaves=10),\n",
    "                         treatment_col='resolution_numeric', outcome_col='rating_numeric', text_col='comment_history_table_string',\n",
    "                         include_cols=['aws_platform_numeric', 'custom_product', 'sentiment', 'support_case_numeric', 'understanding_numeric'])\n",
    "cm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff21b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm.estimate_ate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( cm.estimate_ate(df['comment_history_table_string'].str.contains('good')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( cm.interpret(plot=False)[1][:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1427053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['understanding_numeric'] = df['understanding_numeric'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e1a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edge_properties(df, treatment, outcome, covariates):\n",
    "    \"\"\"Calculate ATE and confidence intervals for a single edge.\"\"\"\n",
    "    cm = CausalInferenceModel(df, \n",
    "                         metalearner_type='t-learner', learner=LGBMClassifier(num_leaves=10),\n",
    "                         treatment_col=treatment, outcome_col=outcome, text_col='comment_history_table_string',\n",
    "                         include_cols=covariates)\n",
    "    cm.fit()\n",
    "    ate = cm.estimate_ate()\n",
    "    return ate\n",
    "\n",
    "potential_treatments = ['support_case_numeric', 'aws_platform_numeric', 'sentiment', 'resolution_numeric', 'understanding_numeric']\n",
    "outcome = 'rating_numeric'\n",
    "covariates = ['aws_platform_numeric', 'custom_product', 'sentiment', 'support_case_numeric', 'resolution_numeric', 'understanding_numeric']\n",
    "\n",
    "edge_properties = {}\n",
    "for treatment in potential_treatments:\n",
    "    edge_properties[treatment] = calculate_edge_properties(\n",
    "        df, treatment, outcome, [c for c in covariates if c != treatment]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae83567",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f4a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"final_df.pkl\", 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1b500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbac9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_individual_edge_properties(row):\n",
    "    tmp_df = pd.DataFrame(row)\n",
    "    t_tmp = tmp_df.T.reset_index()\n",
    "    effect = cm.predict(t_tmp)\n",
    "    return effect[0][0]\n",
    "\n",
    "df['resolution_effect'] = df.apply(calculate_individual_edge_properties, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49aab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"causal_analysis.pkl\", 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e4cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def get_deep_size(obj, seen=None):\n",
    "    \"\"\"\n",
    "    Find the total size of an object and all its contents recursively.\n",
    "    \"\"\"\n",
    "    # Initialize the set of seen objects if needed\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    \n",
    "    # Get object id to track already counted objects\n",
    "    obj_id = id(obj)\n",
    "    \n",
    "    # If we've already seen this object, don't count it again\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    \n",
    "    # Mark this object as seen\n",
    "    seen.add(obj_id)\n",
    "    \n",
    "    # Start with the size of the object itself\n",
    "    size = sys.getsizeof(obj)\n",
    "    \n",
    "    # Handle containers that need recursive measurement\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum(get_deep_size(k, seen) + get_deep_size(v, seen) for k, v in obj.items())\n",
    "    elif isinstance(obj, (list, tuple, set, frozenset)):\n",
    "        size += sum(get_deep_size(item, seen) for item in obj)\n",
    "    \n",
    "    # For custom objects, you might want to add their __dict__ contents\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        size += get_deep_size(obj.__dict__, seen)\n",
    "    \n",
    "    return size\n",
    "\n",
    "def get_size_in_kb(obj):\n",
    "    \"\"\"\n",
    "    Returns the deep size of an object in kilobytes.\n",
    "    \"\"\"\n",
    "    size_in_bytes = get_deep_size(obj)\n",
    "    size_in_kb = size_in_bytes / 1024  # Convert bytes to KB\n",
    "    return size_in_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbfadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dictionary size: {get_size_in_kb(dic):.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ceafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:50].to_csv(\"./sample_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6acc0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
